<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="CaT: Coaching a Teachable Student">
  <meta name="keywords" content="Coaching a Teachable Student, CaT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CaT: Coaching a Teachable Student</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="shortcut icon" href="./favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <meta property="og:site_name" content="CaT: Coaching a Teachable Student" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="CaT: Coaching a Teachable Student" />
  <meta property="og:description" content="Zhang, et al. CaT: Coaching a Teachable Student." />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="CaT: Coaching a Teachable Student" />
  <meta name="twitter:description" content="Zhang, et al. CaT: Coaching a Teachable Student." />

  <script src="https://www.youtube.com/iframe_api"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CaT: Coaching a Teachable Student</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jimuyangz.github.io/">Jimuyang Zhang</a>&emsp;
              <a href="https://tzmhuang.github.io/">Zanming Huang</a>&emsp;
              <a href="https://eshed1.github.io/">Eshed Ohn-Bar</a>&emsp;
              <br />Boston University
              <span class="brmod"></span>CVPR 2023 (Highlight)</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="./resources/CaT.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#method_video"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/h2xlab/CaT"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Slides Link. -->
              <!-- <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-powerpoint"></i>
                  </span>
                  <span>Slides</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="hero-body">
    <div class="columns is-centered">
      <div class="column is-5">
        <img src="./resources/figure1.png" />
        <h2 class="subtitle has-text-centered">
          Single-view view synthesis results on RealEstate10K dataset.
        </h2>
      </div>
    </div>
  </div>
</section> -->



<section class="section">
  <div class="container">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose a novel knowledge distillation framework for
            effectively teaching a sensorimotor student agent to drive
            from the supervision of a privileged teacher agent. Current 
            distillation for sensorimotor agents methods tend to result 
            in suboptimal learned driving behavior by the student,
            which we hypothesize is due to inherent differences between
            the input, modeling capacity, and optimization processes of
            the two agents. We develop a novel distillation scheme that
            can address these limitations and close the gap between the
            sensorimotor agent and its privileged teacher. Our key insight 
            is to design a student which learns to align their input
            features with the teacher’s privileged Bird’s Eye View (BEV)
            space. The student then can benefit from direct supervision
            by the teacher over the internal representation learning. To
            scaffold the difficult sensorimotor learning task, the student
            model is optimized via a student-paced coaching mecha-
            nism with various auxiliary supervision. We further propose
            a high-capacity imitation learned privileged agent that surpasses 
            prior privileged agents in CARLA and ensures the
            student learns safe driving behavior. Our proposed sensorimotor 
            agent results in a robust image-based behavior
            cloning agent in CARLA, improving over current models
            by over 20.6% in driving score without requiring LiDAR,
            historical observations, ensemble of models, on-policy data
            aggregation or reinforcement learning.
          </p>
        </div>
      </div>
    </div>
  </div>
  <!-- Paper video. -->
  <br/>
  <br/>
  <div id="method_video" class="columns is-centered has-text-centered">
    <div class="column is-half">
      <h2 class="title is-3">Video</h2>
      <div class="publication-video">
        <video controls>
          <source src="./resources/CaT_Video.mp4"
                  type="video/mp4">
        </video>
        <!-- <iframe src="https://www.youtube-nocookie.com/embed/SIg_8URon14"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
      </div>
    </div>
  </div>
  <!--/ Paper video. -->

</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our proposed CaT framework 
            enables highly effective knowledge transfer between a privileged 
            teacher and a sensorimotor (i.e., image-based) student. An
            alignment module learns to transform image-based features to the
            teacher’s BEV feature space, where the student can then leverage 
            extensive and direct supervision on its learned intermediate
            representations.
          </p>
          <div class="column">
            <img src="./resources/method.png" />
          </div>

        </div>
      </div>
    </div>
  </div>
</section>




<section class="section id="BibTeX"">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">BibTeX</h2>
        <div class="content has-text-justified">
          <pre><code>@inproceedings{Zhang23CaT,
        title={Coaching a Teachable Student},
        author={Zhang, Jimuyang and Huang, Zanming and Ohn-Bar, Eshed},
        booktitle={CVPR},
        year={2023}
}</code></pre>

        </div>
      </div>
    </div>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a href="./resources/CaT.pdf" class="large-font bottom_buttons">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a href="TODO" class="large-font bottom_buttons" >
        <i class="fab fa-github"></i>
      </a>
      <br />
      <p>Page template borrowed from <a href="https://nerfies.github.io/"><span class="dnerf">D-NeRF</span></a> and <a href="https://worldsheet.github.io/"><span>Worldsheet</span> and <a href="https://zlai0.github.io/VideoAutoencoder/"><span>Video Autoencoder</span>.</p>
    </div>
  </div>
</footer>

</body>
</html>
